# LinkedIn Qualifier v1

> Headless FastAPI backend that qualifies LinkedIn followers against client-specific ICPs extracted from Fathom calls.

---

## ğŸš€ Quick Start

```bash
# 1. Clone and setup
git clone https://github.com/ZainJaffer/ICPv2.git
cd ICPv2

# 2. Create virtual environment
python -m venv venv
.\venv\Scripts\Activate  # Windows
# source venv/bin/activate  # Mac/Linux

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment
# Copy .env.example to .env and fill in your keys:
# - SUPABASE_URL, SUPABASE_KEY
# - APIFY_API_TOKEN
# - OPENAI_API_KEY

# 5. Run the server
uvicorn app.main:app --reload --port 8001
```

**API Docs:** http://localhost:8001/docs

---

## ğŸ“Š Current Status

| Phase | Description | Status |
|-------|-------------|--------|
| 0 | Project Setup | âœ… Complete |
| 1 | Database Schema | âœ… Complete |
| 2 | HTML Ingestion | âœ… Complete & Tested |
| 3 | Enrichment (Apify scraping) | âœ… Complete & Tested (20Ã—5 concurrency) |
| 4a | LangSmith Setup | âœ… Complete (EU endpoint) |
| 4b | pgvector + Embeddings | âœ… Complete |
| 4c | LLM Classifier | âœ… Complete |
| 4d | ICP Matching + Reranker | ğŸ”„ In Progress |
| 4e | Evals Framework | âŒ Not started |
| 5 | CSV Export | ğŸ“ Code written, not tested |
| 6 | Fathom ICP Sync | âŒ Not started |

---

## Business Context

**What we do:** Create LinkedIn content for clients (founders, executives, etc.)

**The workflow:**
1. Client signs up â†’ we do discovery/interview calls (recorded in Fathom)
2. From those calls, we extract WHO the client wants to reach (their ICP)
3. Client exports their LinkedIn followers (HTML file)
4. We score those followers against the client's ICP
5. Output: CSV of high-fit followers the client should engage with

**Key insight:** Each client has their own ICP. This is per-client targeting criteria extracted from their onboarding and interview calls.

---

## Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | FastAPI + Pydantic |
| Database | Supabase + pgvector (state machine + embeddings) |
| AI/LLM | GPT-5-mini (classifier, query parser) |
| Embeddings | OpenAI text-embedding-3-small |
| Reranker | Jina Reranker (cross-encoder) |
| Observability | LangSmith (tracing + evals) |
| Scraping | Apify LinkedIn Profile Scraper |

---

## Project Structure

```
ICPv2/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ clients.py          # Client & ICP management
â”‚   â”‚   â””â”€â”€ batches.py          # Batch operations (enrich, qualify, export)
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ db/
â”‚       â”‚   â””â”€â”€ supabase_client.py    # Database client
â”‚       â”œâ”€â”€ scraping/
â”‚       â”‚   â”œâ”€â”€ apify_scraper.py      # LinkedIn scraping (profiles, posts)
â”‚       â”‚   â”œâ”€â”€ html_parser.py        # Extract URLs from HTML
â”‚       â”‚   â””â”€â”€ profile_id_utils.py   # LinkedIn ID utilities
â”‚       â”œâ”€â”€ matching/
â”‚       â”‚   â”œâ”€â”€ icp_matcher.py        # Current: simple LLM scoring
â”‚       â”‚   â”œâ”€â”€ embeddings.py         # TODO: Generate embeddings
â”‚       â”‚   â”œâ”€â”€ classifier.py         # TODO: LLM industry classifier
â”‚       â”‚   â”œâ”€â”€ query_parser.py       # TODO: ICP â†’ SQL + semantic
â”‚       â”‚   â””â”€â”€ reranker.py           # TODO: Jina reranker
â”‚       â””â”€â”€ enrichment.py             # Orchestrator for scraping + classification
â”œâ”€â”€ inputs/                     # HTML files to process (gitignored)
â”œâ”€â”€ outputs/                    # Generated CSVs
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ process_html.py         # CLI helper for batch processing
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Data Model

```
Client (e.g., "Carl Seidman")
â”œâ”€â”€ ICP Definition (extracted from Fathom calls)
â”‚   â”œâ”€â”€ target_titles: ["CFO", "Finance Director"]
â”‚   â”œâ”€â”€ target_industries: ["SaaS", "Fintech"]
â”‚   â”œâ”€â”€ company_sizes: ["startup", "mid-market"]
â”‚   â””â”€â”€ embedding: [0.012, -0.034, ...]  # Semantic representation
â”‚
â””â”€â”€ Batches (HTML uploads of this client's LinkedIn followers)
    â””â”€â”€ Leads (individual profiles)
        â”œâ”€â”€ status: discovered â†’ enriched â†’ qualified â†’ exported
        â”œâ”€â”€ profile_data: {...}           # Raw scraped data
        â”œâ”€â”€ embedding: [0.023, ...]       # Profile embedding
        â”œâ”€â”€ industry: "SaaS"              # LLM classified
        â”œâ”€â”€ company_type: "startup"       # LLM classified
        â”œâ”€â”€ industry_reasoning: "..."     # LLM explanation
        â”œâ”€â”€ icp_score: 0-100              # Final score
        â””â”€â”€ match_reasoning: "CFO at SaaS startup, matches target"
```

---

## Lead Status State Machine

```
discovered â†’ enriched â†’ qualified â†’ exported
     â†“           â†“           â†“
   failed      failed      failed
     â†“           â†“           â†“
  (retry)    (retry)     (retry)
```

| Status | Description |
|--------|-------------|
| `discovered` | URL extracted from HTML, not yet scraped |
| `enriched` | Profile data scraped and cached |
| `qualified` | Scored against client's ICP |
| `exported` | Included in output CSV |
| `failed` | Error occurred, retry_count tracked |

---

## Database Tables

| Table | Purpose |
|-------|---------|
| `clients` | Client records (name, created_at) |
| `client_icps` | ICP criteria per client (target_titles, industries, company_sizes, embedding) |
| `batches` | HTML upload batches per client |
| `leads` | Individual profiles (status, profile_data, embedding, classification, icp_score) |
| `profile_cache` | Shared cache of scraped profiles (30-day TTL) |
| `fathom_calls` | Tracks processed Fathom calls (Phase 6) |

**New columns for Phase 4:**
- `leads.embedding` - vector(1536) for semantic search
- `leads.industry`, `leads.company_type` - LLM classification
- `leads.industry_reasoning`, `leads.company_reasoning` - LLM explanations
- `client_icps.embedding` - vector(1536) for ICP representation

---

## Build Phases

### Phase 0: Project Setup âœ…
- [x] FastAPI project skeleton
- [x] Supabase connection
- [x] Error handling middleware
- [x] Logging configuration
- [x] Environment variables (.env)

### Phase 1: Database Schema âœ…
- [x] Create Supabase tables
- [x] Create indexes
- [x] Test connections

### Phase 2: HTML Ingestion âœ…
- [x] URL extraction from HTML (handles URN-style LinkedIn IDs)
- [x] Batch creation
- [x] Lead creation with deduplication
- [x] Endpoint: `POST /clients/{id}/ingest`

### Phase 3: Enrichment Service âœ…
- [x] Apify scraper integration
- [x] Cache check logic (30-day TTL)
- [x] URN matching fix (preserve case, match by profileId)
- [x] Status updates
- [x] Endpoint: `POST /batches/{id}/enrich?limit=N`
- [x] **Tested with 5 profiles**
- [x] **Concurrent batching (20 actors Ã— 5 URLs) - TESTED âœ…**

### Phase 4a: LangSmith Setup âœ…
- [x] Add langchain, langchain-openai, langsmith to requirements
- [x] Configure LANGCHAIN_API_KEY, LANGCHAIN_TRACING_V2
- [x] Configure EU endpoint (LANGCHAIN_ENDPOINT)
- [x] Verify traces appear in LangSmith dashboard

### Phase 4b: pgvector + Embeddings âœ…
- [x] Enable pgvector in Supabase
- [x] Add `embedding` column to leads table
- [x] Create embeddings.py service
- [x] Generate embeddings at enrichment time

### Phase 4c: LLM Classifier âœ…
- [x] Add classification columns to leads table
- [x] Create classifier.py service
- [x] Integrate classification into enrichment
- [x] Store `industry`, `company_type`, `industry_reasoning`, `company_reasoning`

### Phase 4d: ICP Matching + Reranker ğŸ”„
- [ ] Expand ICP criteria via LLM for richer embeddings
- [ ] Vector similarity search (pgvector)
- [ ] Add Jina reranker integration
- [ ] Update `POST /batches/{id}/qualify` endpoint

**Note:** SQL filtering skipped - batch sizes (10-1000) are small enough for embeddings-only approach.

### Phase 4e: Evals Framework âŒ
- [ ] Create test dataset (20-50 known profile matches)
- [ ] Build eval runner in LangSmith
- [ ] Measure: embedding recall, reranker precision, end-to-end accuracy

### Phase 5: Export Service ğŸ“
- [x] CSV generation
- [x] Download endpoint: `GET /batches/{id}/export`
- [ ] **Testing pending**

### Phase 6: Fathom ICP Sync âŒ
- [ ] Fathom API client
- [ ] ICP extraction prompt
- [ ] Accumulation logic (expand, don't replace)
- [ ] Endpoint: `POST /clients/{id}/sync-icp`

---

## ICP Matching Architecture

The qualification pipeline uses embeddings + reranker for semantic matching:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. EXPAND ICP (LLM)                                            â”‚
â”‚     "CFO at SaaS startups"                                      â”‚
â”‚     â†’ "CFO, Chief Financial Officer, VP Finance, finance        â”‚
â”‚        executive at SaaS, Software, B2B technology startups"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. VECTOR SEARCH (pgvector)                                    â”‚
â”‚     Generate ICP embedding, find top 50 similar leads           â”‚
â”‚     cosine_similarity(lead.embedding, icp.embedding)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. RERANKER (Jina)                                             â”‚
â”‚     Cross-encoder rescores top 50 with full profile context     â”‚
â”‚     â†’ Returns final ranked list with scores                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why this approach:**
- Batch sizes (10-1000) are small enough for embeddings-only
- LLM expands ICP for richer semantic matching (CFO â‰ˆ VP Finance)
- Reranker provides highest accuracy for final ranking
- Classification (industry/company_type) stored for display, not filtering
- LangSmith traces every step for debugging and evals

---

## Implementation Rules

1. **Async everywhere** - Use `httpx.AsyncClient` for all external API calls
2. **Stateless processing** - Supabase is the source of truth; server can restart and resume
3. **Cache aggressively** - Don't scrape the same profile twice within 30 days
4. **Fail gracefully** - Track retry_count, mark as failed after 3 attempts

---

## Environment Variables

```env
# Database
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_KEY=your_service_role_key

# Scraping
APIFY_API_TOKEN=your_apify_token

# LLM + Embeddings
OPENAI_API_KEY=your_openai_key

# Observability
LANGCHAIN_API_KEY=your_langsmith_api_key
LANGCHAIN_TRACING_V2=true

# Reranker (Phase 4d)
JINA_API_KEY=your_jina_api_key
```

---

## API Endpoints Summary

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/clients` | Create new client |
| POST | `/clients/{id}/sync-icp` | Extract ICP from Fathom calls |
| POST | `/clients/{id}/ingest` | Upload HTML, extract URLs |
| POST | `/batches/{id}/enrich` | Scrape profiles for batch |
| POST | `/batches/{id}/qualify` | Score profiles against ICP |
| GET | `/batches/{id}/export` | Download qualified leads CSV |
